#  Investigaci√≥n: LEX, YACC y su Equivalente en Go

---

## ¬øQu√© es LEX?

**LEX** es una herramienta que se utiliza en compiladores para construir **analizadores l√©xicos** (tambi√©n llamados *tokenizadores*).

Un analizador l√©xico toma una cadena de entrada (como una expresi√≥n l√≥gica) y la divide en componentes m√°s peque√±os llamados **tokens**, que pueden ser:

- Variables (`p`, `q`, `r`, etc.)
- Operadores (`~`, `^`, `o`, `=>`, `<=>`)
- Par√©ntesis `(` y `)`
- Constantes (`0`, `1`)

 **Ejemplo:**

Entrada: `(p=>q)^p`  
Salida del lexer: `(`, `p`, `=>`, `q`, `)`, `^`, `p`

---

## ¬øQu√© es YACC?

**YACC** (*Yet Another Compiler Compiler*) es una herramienta que permite construir **analizadores sint√°cticos** basados en reglas gramaticales.

Toma los tokens generados por LEX y determina si forman una **estructura v√°lida** seg√∫n una **gram√°tica definida**.

Adem√°s, YACC permite construir un **√°rbol de an√°lisis sint√°ctico** (AST), lo cual es √∫til para interpretar o transformar el contenido de una expresi√≥n.

üí¨ En otras palabras:  
YACC valida la **forma** de la expresi√≥n. Se asegura de que los operadores tengan los operandos correctos, los par√©ntesis est√©n bien colocados, y que la estructura de la f√≥rmula cumpla con las reglas del lenguaje.

---

## Equivalente en nuestro lenguaje: Go

En este proyecto decidimos utilizar el lenguaje **Go**, que no tiene una herramienta integrada como LEX o YACC. En su lugar, implementamos **nuestro propio analizador l√©xico (lexer) y sint√°ctico (parser)** de forma manual, usando estructuras y funciones personalizadas.

>  Esta implementaci√≥n fue fuertemente influenciada por un proyecto previo desarrollado en el curso de **Estructura de Datos**, donde tuvimos que construir un **int√©rprete para el lenguaje LISP en Java**. En ese proyecto aprendimos a implementar desde cero un **tokenizador y un lexer**, clasificando s√≠mbolos y estructuras seg√∫n el tipo de expresi√≥n. Esa experiencia fue la base conceptual para replicar un flujo similar en Go, pero orientado al reconocimiento de f√≥rmulas del sistema l√≥gico **L**.

---

### Analizador l√©xico (Lexer)

Creamos una estructura llamada `Lexer` que recorre cada car√°cter de la cadena de entrada y lo clasifica en distintos tipos de tokens seg√∫n el alfabeto permitido:

- Letras `p` a `z` ‚Üí **Variables proposicionales**
- N√∫meros `0` y `1` ‚Üí **Constantes l√≥gicas** (`falso` y `verdadero`)
- S√≠mbolos como `~`, `^`, `o`, `=>`, `<=>`, `(` y `)` ‚Üí **Operadores l√≥gicos y signos**

Cada vez que el lexer reconoce un s√≠mbolo v√°lido, lo devuelve como un **token** que ser√° utilizado por el parser.

---

### Analizador sint√°ctico (Parser)

Creamos otra estructura llamada `Parser` que implementa las **reglas gramaticales** descritas por el sistema l√≥gico **L**. Estas reglas se aplican a los tokens recibidos por el lexer:

- `expr()` reconoce expresiones de tipo **implicaci√≥n (`=>`)** y **doble implicaci√≥n (`<=>`)**
- `term()` reconoce **conjunciones (`^`)** y **disyunciones (`o`)**
- `factor()` reconoce **negaciones (`~`)**, **expresiones entre par√©ntesis**, **variables** y **constantes**

Cada una de estas funciones construye nodos de un **√°rbol sint√°ctico abstracto (AST)**, simulando el comportamiento de un parser generado autom√°ticamente por YACC, pero implementado manualmente.

---

###  ¬øPor qu√© lo hicimos as√≠?

Go no incluye herramientas autom√°ticas como **LEX/YACC** que s√≠ existen en otros lenguajes como C o Python (por ejemplo, el paquete `PLY`). Por ello, decidimos implementar nuestra propia versi√≥n para comprender a profundidad c√≥mo funcionan estos procesos internamente.

Gracias a esta decisi√≥n:

- ‚úÖ **Separar** el an√°lisis l√©xico del an√°lisis sint√°ctico fue m√°s claro y controlado.
- ‚úÖ Pudimos dise√±ar un **AST (√°rbol de sintaxis abstracta)** para representar las expresiones.
- ‚úÖ Pudimos integrar la generaci√≥n de un **grafo dirigido** visualizable con herramientas como **Graphviz**.

---

## Conclusi√≥n

Aunque no usamos herramientas autom√°ticas como LEX y YACC, logramos **replicar su funcionalidad desde cero en Go**. Implementamos un lexer capaz de reconocer tokens v√°lidos del sistema **L** y un parser que valida expresiones seg√∫n su estructura gramatical.

Este proyecto no solo reforz√≥ nuestro conocimiento sobre **aut√≥matas y gram√°ticas**, sino que tambi√©n nos permiti√≥ aplicar y consolidar aprendizajes de cursos anteriores como **Estructura de Datos**, conectando ideas de **interpretaci√≥n de lenguajes** con los fundamentos te√≥ricos de la **l√≥gica matem√°tica**.
